# -*- coding: utf-8 -*-
"""ë¶€ì‚° ë…¸ì¸ë³µì§€íšŒê´€.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ilSzMvOjjnyiTtP5oqLTUrFZT950AI-9

ğŸ“ˆ ë°ì´í„° ì „ì²˜ë¦¬
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')



"""ğŸ“ í‰ê· ì—°ë ¹ ë°ì´í„°"""

df = pd.read_excel("/content/drive/MyDrive/í”„ë¡œì íŠ¸/í‰ê· ì—°ë ¹.xlsx")
df = df.drop(df.index[0])
df = df.drop(df.columns[0], axis=1)
df = df.drop(df.columns[1], axis=1)
df = df.drop(df.columns[1], axis=1)
df = df.set_index('Unnamed: 1')
df.columns = [col.replace('Unnamed: 4', 'í‰ê· ì—°ë ¹') for col in df.columns]
df.index.name = None
df = df.drop(df.index[0])
display(df)

busan = df[df.index.str.contains('ë¶€ì‚°')]
busan = busan.drop(busan.index[:2])

import re
pattern = r".+(ì‹œ|êµ¬)\s?"

busan.index = busan.index.str.replace(pattern, "", regex=True)

busan = busan.drop(index='')
busan = busan.drop(busan.index[-1])
busan = busan.drop(busan.index[-6])

busan = busan.rename(index={'ê¸°ì¥êµ° ê¸°ì¥ì' : 'ê¸°ì¥ì'})
busan = busan.rename(index={'ê¸°ì¥êµ° ì¥ì•ˆì' : 'ì¥ì•ˆì'})
busan = busan.rename(index={'ê¸°ì¥êµ° ì •ê´€ì' : 'ì •ê´€ì'})
busan = busan.rename(index={'ê¸°ì¥êµ° ì¼ê´‘ì' : 'ì¼ê´‘ì'})
busan = busan.rename(index={'ê¸°ì¥êµ° ì² ë§ˆë©´' : 'ì² ë§ˆë©´'})

busan.index = busan.index.str.replace('ì œ', '', regex=False)

display(busan)



"""ğŸ“ ê³ ë ¹ììˆ˜ ë°ì´í„°"""

df2 = pd.read_excel("/content/drive/MyDrive/í”„ë¡œì íŠ¸/ê³ ë ¹ììˆ˜.xlsx")
df2 = df2.drop(df2.index[:1])
df2 = df2.set_index('Unnamed: 1')
df2.index.name = None
df2 = df2.drop(columns=['â€» ë§¤ì›” ë§ì¼ì í†µê³„ í˜„í™©'])
df2 = df2.drop(columns=[df2.columns[1]])
df2 = df2.drop(columns=[df2.columns[1]])
df2 = df2.drop(columns=[df2.columns[-1]])
df2 = df2.drop(columns=[df2.columns[-1]])

df2.columns = [col.replace('Unnamed: 2', 'ì „ì²´ ì¸êµ¬  (ëª…)') for col in df2.columns]
df2.columns = [col.replace('Unnamed: 5', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)') for col in df2.columns]
df2 = df2.drop(df2.index[0])
display(df2)

busan2 = df2[df2.index.str.contains('ë¶€ì‚°')]

import re
pattern = r".+(ì‹œ|êµ¬)\s?"

busan2.index = busan2.index.str.replace(pattern, "", regex=True)

busan2 = busan2.drop(index='') #indexëŠ” ë§¤ê°œë³€ìˆ˜ë¡œ ì‚¬ìš© #busan2.indexëŠ” ì¸ë±ìŠ¤ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ê°ì²´
busan2 = busan2.drop(busan2.index[0])
busan2 = busan2.drop(busan2.index[-1])
busan2 = busan2.drop(busan2.index[-6])

busan2 = busan2.rename(index={'ê¸°ì¥êµ° ê¸°ì¥ì' : 'ê¸°ì¥ì'})
busan2 = busan2.rename(index={'ê¸°ì¥êµ° ì¥ì•ˆì' : 'ì¥ì•ˆì'})
busan2 = busan2.rename(index={'ê¸°ì¥êµ° ì •ê´€ì' : 'ì •ê´€ì'})
busan2 = busan2.rename(index={'ê¸°ì¥êµ° ì¼ê´‘ì' : 'ì¼ê´‘ì'})
busan2 = busan2.rename(index={'ê¸°ì¥êµ° ì² ë§ˆë©´' : 'ì² ë§ˆë©´'})

busan2.index = busan2.index.str.replace('ì œ', '', regex=False)
display(busan2)



"""ğŸ“ ê¸°ì´ˆì—°ê¸ˆìˆ˜ê¸‰ì ë°ì´í„°"""

df3 = pd.read_excel('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„€á…µá„á…©á„‹á…§á†«á„€á…³á†·á„‰á…®á„€á…³á†¸á„Œá…¡.xlsx')
df3 = df3.set_index('ìë©´ë™')
df3.index.name = None
df3 = df3.drop(df3.columns[0], axis=1) #df3 = df3.drop(columns=[df3.columns[0]]) #df3 = df3.drop(columns=['êµ¬êµ°ëª…'])
df3 = df3.drop(df3.columns[0], axis=1)
df3 = df3[~df3.index.str.contains('ì†Œê³„', na=False)]
df3.index = pd.Index(df3.index.to_series().ffill())

gu_indices = df3.index[df3.index.str.endswith('êµ¬')]
df3 = df3.drop(index=gu_indices)

df3 = df3.drop(columns=['ì„±ë³„'])
df3 = df3.drop(columns=['í•©ê³„'])
display(df3)

dong_data = []

row_total = 0
current_dong = None

for index, row in df3.iterrows():
  dong = index

  if dong != current_dong:
    if current_dong is not None:
      dong_data.append([current_dong, row_total])
    row_total = 0
    current_dong = dong

  row_sum = row.sum()
  row_total += row_sum

dong_data.append([current_dong, row_total])
print(dong_data)

dong_df = pd.DataFrame(dong_data)
dong_df = dong_df.set_index(dong_df.columns[0])
dong_df.index.name = None
dong_df.columns = ['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)']
dong_df = dong_df.drop(index = ['ê¸°ì¥êµ°']) #dong_df = dong_df.drop(data.index[-7])
display(dong_df)



busan.index.name = 'ë™'
busan2.index.name = 'ë™'
dong_df.index.name = 'ë™'

merge_busan = pd.merge(busan, busan2, on='ë™', how='outer')
merge_busan = pd.merge(merge_busan, dong_df, on='ë™', how='outer')

merge_busan = merge_busan.drop(index='ì„œ2ë™')
merge_busan = merge_busan.drop(index='ì„œ1ë™')

merge_busan['ì „ì²´ ì¸êµ¬  (ëª…)'] = merge_busan['ì „ì²´ ì¸êµ¬  (ëª…)'].str.replace(',', '')
merge_busan['65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = merge_busan['65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'].str.replace(',', '')

#merge_busan.iloc[merge_busan.index.get_loc('ì„ ë‘êµ¬ë™'), 0] # 0 <-> merge_busan.columns.get_loc(merge_busan.columns[0]) #df.iloc[í–‰ ë²ˆí˜¸, ì—´ ë²ˆí˜¸(ìœ„ì¹˜)]
merge_busan.loc['ì„ ë‘êµ¬ë™', 'í‰ê· ì—°ë ¹'] = 57.7  #df.loc[í–‰ ì¸ë±ì‹±ê°’, ì—´ ì¸ë±ì‹±ê°’]
merge_busan.loc['ì„ ë‘êµ¬ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 2009
merge_busan.loc['ì„ ë‘êµ¬ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 807

merge_busan.loc['ê±°ì œ1ë™', 'í‰ê· ì—°ë ¹'] = 45.1
merge_busan.loc['ê±°ì œ1ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 27817
merge_busan.loc['ê±°ì œ1ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 5761

merge_busan.loc['ê±°ì œ2ë™', 'í‰ê· ì—°ë ¹'] = 39.6
merge_busan.loc['ê±°ì œ2ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 24924
merge_busan.loc['ê±°ì œ2ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 3151

merge_busan.loc['ê±°ì œ3ë™', 'í‰ê· ì—°ë ¹'] = 52.5
merge_busan.loc['ê±°ì œ3ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 9235
merge_busan.loc['ê±°ì œ3ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 3069

merge_busan.loc['ê±°ì œ4ë™', 'í‰ê· ì—°ë ¹'] = 48.8
merge_busan.loc['ê±°ì œ4ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 9430
merge_busan.loc['ê±°ì œ4ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 2461

merge_busan.loc['êµ¬ì„œ1ë™', 'í‰ê· ì—°ë ¹'] = 46.9
merge_busan.loc['êµ¬ì„œ1ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 18274
merge_busan.loc['êµ¬ì„œ1ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 4086

merge_busan.loc['êµ¬ì„œ2ë™', 'í‰ê· ì—°ë ¹'] = 47.8
merge_busan.loc['êµ¬ì„œ2ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 30575
merge_busan.loc['êµ¬ì„œ2ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 7525

merge_busan.loc['êµ¬í‰ë™', 'í‰ê· ì—°ë ¹'] = 43.4
merge_busan.loc['êµ¬í‰ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 12286
merge_busan.loc['êµ¬í‰ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 2132

merge_busan.loc['êµ¬í¬1ë™', 'í‰ê· ì—°ë ¹'] = 49.5
merge_busan.loc['êµ¬í¬1ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 14988
merge_busan.loc['êµ¬í¬1ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 3964

merge_busan.loc['êµ¬í¬2ë™', 'í‰ê· ì—°ë ¹'] = 49.3
merge_busan.loc['êµ¬í¬2ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 23144
merge_busan.loc['êµ¬í¬2ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 5748

merge_busan.loc['êµ¬í¬3ë™', 'í‰ê· ì—°ë ¹'] = 50.6
merge_busan.loc['êµ¬í¬3ë™', 'ì „ì²´ ì¸êµ¬  (ëª…)'] = 17484
merge_busan.loc['êµ¬í¬3ë™', '65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = 4546

merge_busan.loc['ì„œ1ë™'] = [58, 4288, 1751, 415]
merge_busan.loc['ì„œ2ë™'] = [54, 8087, 2771, 489]
merge_busan.loc['êµ¬ì„œ1ë™'] = [46.9, 18274, 4086, 223]
merge_busan.loc['êµ¬ì„œ2ë™'] = [47.8, 30575, 7525, 425]

merge_busan = merge_busan.drop(index=['ì¼ê´‘ë©´'])
merge_busan = merge_busan.dropna(subset=['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)'])

display(merge_busan)
print(merge_busan.isnull().sum())

merge_busan = merge_busan.sort_values(by='ë™', ascending=True)

merge_busan['í‰ê· ì—°ë ¹'] = merge_busan['í‰ê· ì—°ë ¹'].astype(float)
merge_busan['ì „ì²´ ì¸êµ¬  (ëª…)'] = merge_busan['ì „ì²´ ì¸êµ¬  (ëª…)'].astype(int)
merge_busan['65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] = merge_busan['65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'].astype(int)
merge_busan['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)'] = merge_busan['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)'].astype(int)

print(merge_busan.dtypes)

merge_busan['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ë¹„ìœ¨ (ë…¸ì¸)'] = merge_busan['ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)'] / merge_busan['65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)'] * 100
display(merge_busan)



"""ğŸ“ ì˜ë£Œê¸°ê´€ ë°ì´í„°"""

df4 = pd.read_excel('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„‡á…§á†¼á„‹á…¯á†«á„Œá…¥á†¼á„‡á…©á„‰á…¥á„‡á…µá„‰á…³.xlsx')
df4 = df4[df4['ì‹œë„ì½”ë“œëª…'] == 'ë¶€ì‚°']
df4 = df4.drop(columns=['ì¢…ë³„ì½”ë“œ', 'ì•”í˜¸í™”ìš”ì–‘ê¸°í˜¸', 'ì‹œë„ì½”ë“œ', 'ì‹œë„ì½”ë“œëª…', 'ì‹œêµ°êµ¬ì½”ë“œ', 'ì‹œêµ°êµ¬ì½”ë“œëª…', 'ìš°í¸ë²ˆí˜¸', 'ì „í™”ë²ˆí˜¸', 'ë³‘ì›í™ˆí˜ì´ì§€', 'ê°œì„¤ì¼ì', 'ì´ì˜ì‚¬ìˆ˜', 'ì˜ê³¼ì¼ë°˜ì˜ ì¸ì›ìˆ˜', 'ì˜ê³¼ì¸í„´ ì¸ì›ìˆ˜', 'ì˜ê³¼ë ˆì§€ë˜íŠ¸ ì¸ì›ìˆ˜', 'ì˜ê³¼ì „ë¬¸ì˜ ì¸ì›ìˆ˜', 'ì¹˜ê³¼ì¼ë°˜ì˜ ì¸ì›ìˆ˜', 'ì¹˜ê³¼ì¸í„´ ì¸ì›ìˆ˜', 'ì¹˜ê³¼ë ˆì§€ë˜íŠ¸ ì¸ì›ìˆ˜', 'ì¹˜ê³¼ì „ë¬¸ì˜ ì¸ì›ìˆ˜', 'í•œë°©ì¼ë°˜ì˜ ì¸ì›ìˆ˜', 'í•œë°©ì¸í„´ ì¸ì›ìˆ˜', 'í•œë°©ë ˆì§€ë˜íŠ¸ ì¸ì›ìˆ˜', 'í•œë°©ì „ë¬¸ì˜ ì¸ì›ìˆ˜', 'ì¡°ì‚°ì‚¬ ì¸ì›ìˆ˜'])
df4 = df4.set_index('ìë©´ë™')
df4 = df4.sort_values(by='ìë©´ë™', ascending=True)
hospital = df4[~df4['ì¢…ë³„ì½”ë“œëª…'].str.contains('ë³´ê±´')]
d_hospital = hospital.drop(columns=['ì£¼ì†Œ', 'ì¢…ë³„ì½”ë“œëª…'])
display(d_hospital)



"""ğŸ“ ê³µê³µë³´ê±´ê¸°ê´€ ë°ì´í„°"""

bogun = df4[(df4['ì¢…ë³„ì½”ë“œëª…'] == 'ë³´ê±´ì†Œ') | (df4['ì¢…ë³„ì½”ë“œëª…'] == 'ë³´ê±´ì§€ì†Œ') | (df4['ì¢…ë³„ì½”ë“œëª…'] == 'ë³´ê±´ì§„ë£Œì†Œ')] #df4[df4['ì¢…ë³„ì½”ë“œëª…'].isin(['ë³´ê±´ì†Œ', 'ë³´ê±´ì§€ì†Œ', 'ë³´ê±´ì§„ë£Œì†Œ'])]
bogun = bogun.sort_values(by='ìë©´ë™', ascending=True)
d_bogun = bogun.drop(columns=['ì¢…ë³„ì½”ë“œëª…', 'ì£¼ì†Œ'])
display(d_bogun)



"""ğŸ“ ë²„ìŠ¤ ì •ë¥˜ì¥ ë°ì´í„°"""

bus = pd.read_csv('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„‡á…®á„‰á…¡á†« á„‡á…¥á„‰á…³á„Œá…¥á†¼á„…á…²á„Œá…¡á†¼.csv',encoding='cp949')
bus = bus[bus['strd_date'] == 20250110]
bus = bus[['stps_id', 'stps_nm', 'stps_lgd_cdn_val', 'stps_ltd_cdn_val']]

bus = bus.rename(columns={'stps_id' : 'ì •ë¥˜ì¥ë²ˆí˜¸'})
bus = bus.rename(columns={'stps_nm' : 'ì •ë¥˜ì¥ëª…'})
bus = bus.rename(columns={'stps_lgd_cdn_val' : 'ê²½ë„'})
bus = bus.rename(columns={'stps_ltd_cdn_val' : 'ìœ„ë„'})

bus = bus.reset_index()
bus = bus.drop(columns=['index'])
display(bus)

busstop = bus['ì •ë¥˜ì¥ë²ˆí˜¸'].value_counts()
busstop = pd.DataFrame(busstop)
busstop = busstop.reset_index()
busstop = busstop.rename(columns={'count':'ë°©ë¬¸íšŸìˆ˜'})
display(busstop)

bus_score = pd.merge(busstop, bus, on='ì •ë¥˜ì¥ë²ˆí˜¸', how='left')
bus_score = bus_score.drop_duplicates()
display(bus_score)



""" ğŸ“ ì§€ë¦¬ ë°ì´í„°"""

!pip install folium
!pip install geopandas

!pip install --upgrade fiona

import folium
import geopandas as gpd
from folium.plugins import HeatMap
from shapely.geometry import Point,Polygon,MultiPoint
from shapely.geometry import shape,LineString
from shapely.ops import cascaded_union

gdf_korea = gpd.read_file('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/BND_ADM_DONG_PG.shp')

codes = ['21010', '21020', '21030', '21040', '21050', '21060', '21070', '21080', '21090', '21100', '21110', '21120', '21130', '21140', '21150', '21510']
gdf_bs = gdf_korea[gdf_korea['ADM_CD'].str[:5].isin(codes)]

gdf_bs['geometry'] = gdf_bs['geometry'].apply(lambda x: shape(x).buffer(0))
gdf_bs = gdf_bs.to_crs('EPSG:4326')
display(gdf_bs)



"""ë²„ìŠ¤ì •ë¥˜ì¥ ë°ì´í„° í–‰ì •ë™ ì ìš©"""

bus_score['ë™'] = None
for i, point in bus_score.iterrows():
  latitude = point['ìœ„ë„']
  longitude = point['ê²½ë„']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      bus_score.at[i, 'ë™'] = area['ADM_NM']
      break
display(bus_score)

i_bus_score = bus_score.dropna()
i_bus_score = i_bus_score.groupby('ë™')

f_bus = i_bus_score['ë°©ë¬¸íšŸìˆ˜'].sum()
n_bus = i_bus_score['ì •ë¥˜ì¥ëª…'].count()
display(f_bus)
display(n_bus)



"""ì˜ë£Œê¸°ê´€ ë°ì´í„° í–‰ì •ë™ ì ìš©"""

d_hospital['ë™'] = None
for i, point in d_hospital.iterrows():
  latitude = point['ì¢Œí‘œ(Y)']
  logitude = point['ì¢Œí‘œ(X)']
  point_geom = Point(logitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      d_hospital.at[i, 'ë™'] = area['ADM_NM']
      break

d_hospital = d_hospital.dropna(subset={'ë™'})
d_hospital = d_hospital.groupby('ë™')
d_hospital = d_hospital['ë™'].count()
d_hospital = d_hospital.to_frame()
d_hospital = d_hospital.rename(columns = {'ë™' : 'ì˜ë£Œê¸°ê´€'})
display(d_hospital)



"""ê³µê³µë³´ê±´ê¸°ê´€ ë°ì´í„° í–‰ì •ë™ ì ìš©"""

d_bogun['ë™'] = None
for i, point in d_bogun.iterrows():
  latitude = point['ì¢Œí‘œ(Y)']
  longitude = point['ì¢Œí‘œ(X)']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      d_bogun.at[i, 'ë™'] = area['ADM_NM']
      break

d_bogun = d_bogun[['ë™']]
d_bogun = d_bogun.groupby('ë™')
d_bogun = d_bogun['ë™'].count()
d_bogun = d_bogun.to_frame()
d_bogun = d_bogun.rename(columns={'ë™' : 'ê³µê³µë³´ê±´ê¸°ê´€'})
display(d_bogun)



"""ğŸ“ ë…¸ì¸ë³µì§€ê´€ ë°ì´í„°"""

df5 = pd.read_csv('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„‚á…©á„‹á…µá†«á„‡á…©á†¨á„Œá…µá„€á…ªá†«.csv', encoding='cp949')

df5['ë™'] = None
for i, point in df5.iterrows():
  latitude = point['ìœ„ë„']
  longitude = point['ê²½ë„']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      df5.at[i, 'ë™'] = area['ADM_NM']
      break
display(df5)

grouped_df5 = df5.groupby('ë™')
senior_centor = grouped_df5['ë™'].count()
senior_centor = senior_centor.to_frame()
senior_centor = senior_centor.rename(columns={'ë™' : 'ë…¸ì¸ë³µì§€íšŒê´€'})
display(senior_centor)



"""ğŸ“ ì¸êµ¬ë°€ë„ ë°ì´í„°"""

df6 = pd.read_excel('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„‹á…µá†«á„€á…®á„†á…µá†¯á„ƒá…©.xls')

df6 = df6.drop(columns=['ìˆœìœ„', 'ì§‘ê³„êµ¬ë²ˆí˜¸', 'ë¹„ìœ¨(%)'])
df6 = df6.set_index('í•­ëª©')
df6 = df6.rename(columns={'ê°’' : 'ì¸êµ¬ë°€ë„ (ëª…/ã¢)'})
df6.index.name = 'ë™'
display(df6)



"""ğŸ“ ë…¸ë ¹í™”ì§€ìˆ˜ ë°ì´í„°"""

df7 = pd.read_excel('/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„‚á…©á„…á…§á†¼á„’á…ªá„Œá…µá„‰á…®.xls')

df7 = df7.drop(columns=['ìˆœìœ„', 'ì§‘ê³„êµ¬ë²ˆí˜¸', 'ë¹„ìœ¨(%)'])
df7 = df7.set_index('í•­ëª©')
df7 = df7.rename(columns={'ê°’' : 'ë…¸ë ¹í™”ì§€ìˆ˜'})
df7.index.name = 'ë™'
display(df7)



"""ğŸ“ˆ ë¶„ì„"""

data = pd.merge(merge_busan, d_hospital, on='ë™', how='outer')
data = pd.merge(data, d_bogun, on='ë™', how='outer')
data = pd.merge(data, f_bus, on='ë™', how='outer')
data = pd.merge(data, n_bus, on='ë™', how='outer')

data = data.fillna(0)
data['ì˜ë£Œê¸°ê´€'] = data['ì˜ë£Œê¸°ê´€'].astype(int)
data['ê³µê³µë³´ê±´ê¸°ê´€'] = data['ê³µê³µë³´ê±´ê¸°ê´€'].astype(int)
data['ë°©ë¬¸íšŸìˆ˜'] = data['ë°©ë¬¸íšŸìˆ˜'].astype(int)
data['ì •ë¥˜ì¥ëª…'] = data['ì •ë¥˜ì¥ëª…'].astype(int)

data = pd.merge(data, df6, on='ë™', how='outer')
data = pd.merge(data, df7, on='ë™', how='outer')
display(data)

print(data.isnull().sum())

scaler = StandardScaler()
data_scale = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)
data_scale = data_scale*10 + 50
display(data_scale)

#ìŠ¤ì¼€ì¼ë§ -> scree plot í†µí•´ ìµœì ì˜ ì£¼ì„±ë¶„ ê°¯ìˆ˜ ì„¤ì • -> ìŠ¤ì¼€ì¼ë§ëœ ìë£Œ í†µí•´ ì£¼ì„±ë¶„ë¶„ì„ -> ì£¼ì„±ë¶„ ì ìˆ˜ í†µí•´ ê° ì£¼ì„±ë¶„ì— ëŒ€í•´ ë…¸ì¸ë³µì§€ê´€ ìˆëŠ” ê³³ ì—†ëŠ” ê³³ í™•ë¥ ë°€ë„í•¨ìˆ˜ -> ë…¸ì¸ë³µì§€íšŒê´€ ìœ ë¬´ì— ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì£¼ì„±ë¶„ 2ê°œ ì„ ì • -> pc1ê³¼ pc4ì— ëŒ€í•´ kmeans clustering
#ìŠ¤ì¼€ì¼ë§ -> ë…¸ì¸ë³µì§€íšŒê´€ ìˆëŠ” ê³³ ì—†ëŠ” ê³³ í™•ë¥ ë°€ë„í•¨ìˆ˜ -> ë…¸ì¸ë³µì§€íšŒê´€ ìœ ë¬´ì— ì˜í–¥ë ¥ìˆëŠ” ë³€ìˆ˜ ì°¨ë“± ê°€ì¤‘ì¹˜ ë¶€ì—¬ -> ì¬ìŠ¤ì¼€ì¼ë§ -> ì§€í‘œ ìƒì„±í•˜ì—¬ ì‹œê°í™”



"""ã€½ scree plot"""

from sklearn.decomposition import PCA

pca_model = PCA()
pca_result = pca_model.fit_transform(data_scale)

print(pca_result)

plt.plot(range(1, len(pca_model.explained_variance_ratio_)+1), pca_model.explained_variance_ratio_, marker='o')
plt.xlabel('Number of Components')
plt.ylabel('Explained Variance')
plt.title('Scree Plot')
plt.show()

#ì£¼ì„±ë¶„ ê°œìˆ˜ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ scree plot ë¶„ì„ ê²°ê³¼ ê·¸ë˜í”„ê°€ 4ì§€ì ê¹Œì§€ ê¸‰ê²©í•˜ê²Œ í•˜ë½í•˜ê³  ê·¸ ë’¤ë¡œëŠ” ì™„ë§Œí•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ ë”°ë¼ì„œ ì—˜ë³´ìš° í¬ì¸íŠ¸ê°€ ì£¼ì„±ë¶„ì´ 4ê°œì¼ ë•Œë¡œ ê°€ì •, ì£¼ì„±ë¶„ì´ ë” ë§ì„ ë•Œì™€ ì°¨ì´ê°€ í¬ê²Œ ë‚˜ì§€ ì•ŠëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ

#scree plotì„ í†µí•´ ì–»ì€ ì£¼ì„±ë¶„ ê°œìˆ˜ë¥¼ í†µí•´ 11ê°œì˜ ì°¨ì›ì„ 4ê°œì˜ ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œì‹œí‚¨ ë°ì´í„°(ì£¼ì„±ë¶„ ì ìˆ˜)
pca = PCA(n_components=4)
pca_result = pca.fit_transform(data_scale)
print(pca_result)

#PCA ë¶„ì‚° ì„¤ëª…ë ¥
pca_variance_ratio = pca.explained_variance_ratio_
print(pca_variance_ratio)

#ì£¼ì„±ë¶„ê³„ìˆ˜
loadings = pca.components_
print(loadings)

pc = pd.DataFrame(loadings.T, index=data_scale.columns, columns=['PC1', 'PC2', 'PC3', 'PC4'])
display(pc)



"""ã€½ í™•ë¥ ë°€ë„í•¨ìˆ˜"""

dataframe = pd.merge(data, senior_centor, on='ë™', how='outer')
dataframe = dataframe.fillna(0)
dataframe['ë…¸ì¸ë³µì§€íšŒê´€'] = dataframe['ë…¸ì¸ë³µì§€íšŒê´€'].astype(int)
display(dataframe)

#ë…¸ì¸ë³µì§€íšŒê´€ ìœ ë¬´ì— ë”°ë¼ ë°ì´í„° ë¶„ë¦¬
df_no_senior_centor = dataframe[dataframe['ë…¸ì¸ë³µì§€íšŒê´€'] == 0]
df_senior_centor = dataframe[dataframe['ë…¸ì¸ë³µì§€íšŒê´€'] == 1]
display(df_no_senior_centor)
display(df_senior_centor)

#ë¶„ë¦¬ëœ ë°ì´í„° ê° ìŠ¤ì¼€ì¼ë§ í›„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
scaler = StandardScaler()

no_senior_scaled = scaler.fit_transform(df_no_senior_centor)
no_senior_scaled_df = pd.DataFrame(no_senior_scaled, columns=df_no_senior_centor.columns)
display(no_senior_scaled_df)

senior_scaled = scaler.fit_transform(df_senior_centor)
senior_scaled_df = pd.DataFrame(senior_scaled, columns=df_senior_centor.columns)
display(senior_scaled_df)

#í™•ë¥ ë°€ë„í•¨ìˆ˜ ìƒì„±
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm

plt.rc("font", family="Liberation Serif")
plt.rcParams["axes.unicode_minus"] = False

# ë¹„êµí•  ë³€ìˆ˜ ëª©ë¡
columns = [
    "í‰ê· ì—°ë ¹", "ì „ì²´ ì¸êµ¬  (ëª…)", "65ì„¸ ì´ìƒ ê³ ë ¹ì (ëª…)", "ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜ (ë…¸ì¸)",
    "ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ë¹„ìœ¨ (ë…¸ì¸)", "ì˜ë£Œê¸°ê´€", "ê³µê³µë³´ê±´ê¸°ê´€", "ì •ë¥˜ì¥ëª…", "ë°©ë¬¸íšŸìˆ˜", "ì¸êµ¬ë°€ë„ (ëª…/ã¢)",
    "ë…¸ë ¹í™”ì§€ìˆ˜"
]

# ê·¸ë˜í”„ ì„¤ì •
plt.figure(figsize=(15, 24))
for i, col in enumerate(columns, 1):
    plt.subplot(6, 2, i)
    sns.kdeplot(no_senior_scaled_df[col], label="x", fill=True, alpha=0.5)
    sns.kdeplot(senior_scaled_df[col], label="o", fill=True, alpha=0.5)
    plt.legend()
    plt.title(f"{col}ì— ë”°ë¥¸ í™•ë¥ ë°€ë„í•¨ìˆ˜")
plt.tight_layout()
plt.show()

# âœ… ê¸°ì¡´ KDE ê°€ì¤‘ì¹˜ ê¸°ì¡´ KDE ê¸°ë°˜ ê°€ì¤‘ì¹˜ëŠ” ë³€ìˆ˜ë³„ ë¶„í¬ì˜ ì°¨ì´ë¥¼ ê³ ë ¤í•´ì„œ ì„¤ì •í–ˆì–´. ì¦‰, ë³€ìˆ˜ë“¤ì´ ì§€ì—­ë³„ë¡œ ì–¼ë§ˆë‚˜ ì°¨ì´ê°€ ë‚˜ëŠ”ì§€ë¥¼ ë°˜ì˜
#KDE ê°€ì¤‘ì¹˜ ì„¤ì • ë…¼ë¦¬ KDE(ì»¤ë„ ë°€ë„ ì¶”ì •, Kernel Density Estimation) ê·¸ë˜í”„ë¥¼ ë¶„ì„í•œ ê²°ê³¼,
#ê°’ì˜ ë¶„í¬ ì°¨ì´ê°€ í° ë³€ìˆ˜ â†’ ë†’ì€ ê°€ì¤‘ì¹˜ ê°’ì˜ ì°¨ì´ê°€ ì ì€ ë³€ìˆ˜ â†’ ë‚®ì€ ê°€ì¤‘ì¹˜
#kde_weights = np.array([0.05, 0.05, 0.10, 0.20, 0.20, 0.15, 0.15, 0.05, 0.05, 0.05, 0.10])



"""ã€½ ë³€ìˆ˜ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° í›„ ì§€í‘œ ì„¤ì •"""

# âœ… PCA ë¶„ì‚° ì„¤ëª…ë ¥
pca_variance_ratio = np.array([0.36063063, 0.22569202, 0.13786348, 0.08059372])

# âœ… PCA ë¡œë”©ê°’
pca_loadings = loadings.T

# âœ… PCA ê°€ì¤‘ì¹˜ ê³„ì‚° (ì ˆëŒ“ê°’ Ã— ë¶„ì‚° ì„¤ëª…ë ¥)
pca_weights = np.sum(np.abs(pca_loadings) * pca_variance_ratio, axis=1)

# âœ… ê¸°ì¡´ KDE ê°€ì¤‘ì¹˜
kde_weights = np.array([0.05, 0.05, 0.10, 0.20, 0.20, 0.15, 0.15, 0.05, 0.05, 0.05, 0.10])

# âœ… ìµœì¢… ê°€ì¤‘ì¹˜ (PCA 50% + KDE 50%)
final_weights = 0.5 * pca_weights + 0.5 * kde_weights

# âœ… ê°€ì¤‘ì¹˜ DataFrame ìƒì„±
columns = ["í‰ê· ì—°ë ¹", "ì „ì²´ ì¸êµ¬", "65ì„¸ ì´ìƒ ê³ ë ¹ì", "ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ìˆ˜", "ê¸°ì´ˆì—°ê¸ˆ ìˆ˜ê¸‰ì ë¹„ìœ¨",
           "ì˜ë£Œê¸°ê´€", "ê³µê³µë³´ê±´ê¸°ê´€", "ë°©ë¬¸íšŸìˆ˜", "ì •ë¥˜ì¥ ìˆ˜", "ì¸êµ¬ë°€ë„", "ë…¸ë ¹í™”ì§€ìˆ˜"]
weights_df = pd.DataFrame({"ë³€ìˆ˜": columns, "ìµœì¢… ê°€ì¤‘ì¹˜": final_weights})

# âœ… ê²°ê³¼ ì¶œë ¥
display(weights_df)

# âœ… ì§€ì—­ë³„ ì§€í‘œ ê³„ì‚° (ê° ë³€ìˆ˜ ê°’ * ê°€ì¤‘ì¹˜ í•©)
region_scores = np.dot(data_scale, final_weights)

# âœ… ê²°ê³¼ ì¶œë ¥
regions = data.index.tolist()
result_df = pd.DataFrame({"í–‰ì •ë™": regions, "ì§€í‘œ": region_scores})
display(result_df)

#ì§€í‘œì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ
scaler = StandardScaler()
dataframe = pd.DataFrame(scaler.fit_transform(dataframe), columns=dataframe.columns)
dataframe = dataframe*10 + 50

dataframe = pd.concat([dataframe, result_df], axis=1)
dataframe = dataframe.sort_values(by='ì§€í‘œ', ascending=False)
display(dataframe)



"""ã€½ ì§€ë„ ì‹œê°í™”"""

result_df = result_df.set_index('í–‰ì •ë™')
gdf_index = pd.merge(gdf_bs, result_df['ì§€í‘œ'], left_on='ADM_NM', right_index=True)
display(gdf_index)

#ì§€í‘œì— ë”°ë¥¸ ì‹œê°í™”
m=folium.Map(location=[35.1796, 129.0756], zoom_start=11)

folium.Choropleth(
    geo_data=gdf_index,
    data=gdf_index,
    columns=['ADM_NM', 'ì§€í‘œ'],
    key_on='feature.properties.ADM_NM',
    fill_color='YlGnBu',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='ì§€í‘œ'
).add_to(m)
folium.GeoJson(gdf_index).add_to(m)

display(m)

#í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë…¸ì¸ë³µì§€íšŒê´€ ìœ„ì¹˜ ì¶”ê°€
for idx, row in df5.iterrows():
  folium.CircleMarker(
      location=[row['ìœ„ë„'], row['ê²½ë„']],
      radius=15,
      color='red',
      fill=True,
      weight=0.1
  ).add_to(m)

display(m)

#ì§€í‘œë¥¼ í†µí•œ ì‹œê°í™”ì™€ í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë…¸ì¸ë³µì§€íšŒê´€ì˜ ìœ„ì¹˜ íŒŒì•…ì„ í†µí•´ ì§€ì—­ì„ ê¸ˆê³¡ë™ìœ¼ë¡œ ì„ ì •

plotly



"""ã€½ ê¸ˆê³¡ë™ ì§€ê°€ ë°ì´í„°"""

import requests
import pandas as pd

file_path = '/content/drive/MyDrive/á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/á„€á…³á†·á„€á…©á†¨á„ƒá…©á†¼ á„Œá…µá„€á…¡.xlsx'

land_gumgok = pd.read_excel(file_path)
land_gumgok = land_gumgok.dropna()
land_gumgok.columns = land_gumgok.iloc[0]
land_gumgok.drop(index=1, inplace=True)
land_gumgok.index = land_gumgok['ì¼ë ¨ ë²ˆí˜¸']
land_gumgok.columns.name = None
land_gumgok = land_gumgok.drop(columns=['ì¼ë ¨ ë²ˆí˜¸', 'ì§€ ëª©', 'ì§€ë¦¬ì  ìœ„ì¹˜', 'í˜•ìƒ ì§€ì„¸']) #ì—´ ì‚­ì œ #land_gumgok.drop(land_gumgok.columns[0], axis=1)
land_gumgok = land_gumgok.reset_index(drop=True)

display(land_gumgok)

#ìœ„ë„ ê²½ë„ ì¶”ê°€
land_gumgok['ìœ„ë„'] = None
land_gumgok['ê²½ë„'] = None

latitude_values = [35.264806992462, 35.2628328140424, 35.266174832219, 35.266892790289, 35.2641924114557, 35.2657228187836, 35.265631953833, 35.2653420946788, 35.2649738413425, 35.2651331955503, 35.2649255240571, 35.2644468402776, 35.2645766278052, 35.2644330101972, 35.2639785286683, 35.2618801447748, 35.2623833498672, 35.2623142473772, 35.2631223714243, 35.2606828277845]
longitude_values = [129.038142717264, 129.022797131054, 129.017764116584, 129.017968937041, 129.020164496182, 129.016747972491, 129.017452117121, 129.017741265492, 129.019401364743, 129.016569421171, 129.017026081343, 129.017198364434, 129.016051298328, 129.016547011818, 129.01621897914, 129.021037807019, 129.016026837158, 129.015501364102, 129.019242131179, 129.015196386607]

for i in range(len(latitude_values)):
    if i in land_gumgok.index:
      land_gumgok.loc[i, 'ìœ„ë„'] = latitude_values[i]

for i in range(len(longitude_values)):
    if i in land_gumgok.index:
      land_gumgok.loc[i, 'ê²½ë„'] = longitude_values[i]

display(land_gumgok)



"""ã€½ ê¸ˆê³¡ë™ ì§€ê°€ ì‹œê°í™”"""

import folium
import pandas as pd
import geopandas as gpd
from folium.plugins import HeatMap
from shapely.geometry import Point,Polygon,MultiPoint
from shapely.geometry import shape,LineString
from shapely.ops import cascaded_union
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import matplotlib.colors as colors
from matplotlib.colors import LinearSegmentedColormap

data_dict = {}
for index, row in land_gumgok.iterrows():
    data_dict[index] = {'ìœ„ë„': None, 'ê²½ë„': None}

# ìœ„ë„, ê²½ë„ ê°’ì„ ì°¨ë¡€ëŒ€ë¡œ ë„£ì–´ì¤Œ
for index, (latitude, longitude) in enumerate(zip(latitude_values, longitude_values)):
    if index in data_dict:
        data_dict[index]['ìœ„ë„'] = latitude
        data_dict[index]['ê²½ë„'] = longitude

# ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°í”„ë ˆì„ ì—…ë°ì´íŠ¸
for index, values in data_dict.items():
    land_gumgok.loc[index, 'ìœ„ë„'] = values['ìœ„ë„']
    land_gumgok.loc[index, 'ê²½ë„'] = values['ê²½ë„']

# ì§€ë„ ìƒì„±
map_center = [land_gumgok['ìœ„ë„'].mean(), land_gumgok['ê²½ë„'].mean()]  # ìœ„ë„ì™€ ê²½ë„ì˜ í‰ê· ê°’ìœ¼ë¡œ ì§€ë„ ì¤‘ì‹¬ ì„¤ì •
m = folium.Map(location=map_center, zoom_start=15)

# ê³µì‹œì§€ê°€ ì •ê·œí™”
min_price = land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'].min()
max_price = land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'].max()
land_gumgok['normalized_price'] = (land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'] - min_price) / (max_price - min_price)

# ìƒ‰ìƒ ë§µ ìƒì„± (YlGn ì‚¬ìš©)
cmap = cm.get_cmap('YlGn')

# ì›í˜• ë§ˆì»¤ ì¶”ê°€
for index, row in land_gumgok.iterrows():
    price = row['normalized_price']
    color = colors.to_hex(cmap(price))  # ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ìƒ‰ìƒ ê²°ì •
    radius = 10 # ëª¨ë“  ì›ì˜ í¬ê¸°ë¥¼ í†µì¼ì‹œì¼°ìŠµë‹ˆë‹¤.
    folium.CircleMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        radius=radius,  # ëª¨ë“  ì›ì˜ í¬ê¸°ë¥¼ í†µì¼ì‹œì¼°ìŠµë‹ˆë‹¤.
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        popup=f"ì†Œì¬ì§€: {row['ì†Œì¬ì§€']}<br>ê³µì‹œì§€ê°€: {row['ê³µì‹œì§€ê°€ ( ì›/ ã¡)']}"  # íŒì—… ì¶”ê°€
    ).add_to(m)

    # ì¸ë±ìŠ¤ í…ìŠ¤íŠ¸ ë ˆì´ë¸”
    folium.map.Marker(
        [row['ìœ„ë„'], row['ê²½ë„']],
        icon=folium.DivIcon(html=f"<div style='font-size: 8pt; color : black; font-weight: bold'>{index}</div>")
    ).add_to(m)

# ì§€ë„ í‘œì‹œ
display(m)

#ë§¹ì§€ì™€ ì•„íŒŒë“œì§€ëŒ€ì¸ 0, 1, 15, 19ë²ˆ ë°ì´í„° ì‚­ì œ
land_gumgok = land_gumgok.drop([0, 1, 15, 19])

data_dict = {}
for index, row in land_gumgok.iterrows():
    data_dict[index] = {'ìœ„ë„': None, 'ê²½ë„': None}

# ìœ„ë„, ê²½ë„ ê°’ì„ ì°¨ë¡€ëŒ€ë¡œ ë„£ì–´ì¤Œ
for index, (latitude, longitude) in enumerate(zip(latitude_values, longitude_values)):
    if index in data_dict:
        data_dict[index]['ìœ„ë„'] = latitude
        data_dict[index]['ê²½ë„'] = longitude

# ìƒˆë¡œìš´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ì„œ ë°ì´í„°í”„ë ˆì„ ì—…ë°ì´íŠ¸
for index, values in data_dict.items():
    land_gumgok.loc[index, 'ìœ„ë„'] = values['ìœ„ë„']
    land_gumgok.loc[index, 'ê²½ë„'] = values['ê²½ë„']

# ì§€ë„ ìƒì„±
map_center = [land_gumgok['ìœ„ë„'].mean(), land_gumgok['ê²½ë„'].mean()]  # ìœ„ë„ì™€ ê²½ë„ì˜ í‰ê· ê°’ìœ¼ë¡œ ì§€ë„ ì¤‘ì‹¬ ì„¤ì •
m = folium.Map(location=map_center, zoom_start=15)

# ê³µì‹œì§€ê°€ ì •ê·œí™”
min_price = land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'].min()
max_price = land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'].max()
land_gumgok['normalized_price'] = (land_gumgok['ê³µì‹œì§€ê°€ ( ì›/ ã¡)'] - min_price) / (max_price - min_price)

# ìƒ‰ìƒ ë§µ ìƒì„± (YlGn ì‚¬ìš©)
cmap = cm.get_cmap('YlGn')

# ì›í˜• ë§ˆì»¤ ì¶”ê°€
for index, row in land_gumgok.iterrows():
    price = row['normalized_price']
    color = colors.to_hex(cmap(price))  # ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ìƒ‰ìƒ ê²°ì •
    radius = 10 # ëª¨ë“  ì›ì˜ í¬ê¸°ë¥¼ í†µì¼ì‹œì¼°ìŠµë‹ˆë‹¤.
    folium.CircleMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        radius=radius,  # ëª¨ë“  ì›ì˜ í¬ê¸°ë¥¼ í†µì¼ì‹œì¼°ìŠµë‹ˆë‹¤.
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        popup=f"ì†Œì¬ì§€: {row['ì†Œì¬ì§€']}<br>ê³µì‹œì§€ê°€: {row['ê³µì‹œì§€ê°€ ( ì›/ ã¡)']}"  # íŒì—… ì¶”ê°€
    ).add_to(m)

    # ì¸ë±ìŠ¤ í…ìŠ¤íŠ¸ ë ˆì´ë¸”
    folium.map.Marker(
        [row['ìœ„ë„'], row['ê²½ë„']],
        icon=folium.DivIcon(html=f"<div style='font-size: 8pt; color : black; font-weight: bold'>{index}</div>")
    ).add_to(m)

# ì§€ë„ í‘œì‹œ
display(m)



"""ã€½ ê¸ˆê³¡ë™ ë²„ìŠ¤ì •ë¥˜ì¥ ë°©ë¬¸íšŸìˆ˜ ë°ì´í„° ì¶”ê°€"""

bus_gumgok = bus_score[bus_score['ë™'] == 'ê¸ˆê³¡ë™']
display(bus_gumgok)

# ë°©ë¬¸ íšŸìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤
min_visits = bus_gumgok['ë°©ë¬¸íšŸìˆ˜'].min()
max_visits = bus_gumgok['ë°©ë¬¸íšŸìˆ˜'].max()
bus_gumgok['normalized_visits'] = (bus_gumgok['ë°©ë¬¸íšŸìˆ˜'] - min_visits) / (max_visits - min_visits)

# ìƒ‰ìƒ ë§µì„ ìƒì„±í•©ë‹ˆë‹¤ (ì˜ˆ: YlGnBu ì‚¬ìš©)
cmap = cm.get_cmap('Oranges')

for index, row in bus_gumgok.iterrows():
    # ì •ê·œí™”ëœ ë°©ë¬¸ íšŸìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒ‰ìƒê³¼ ë°˜ì§€ë¦„ì„ ê²°ì •í•©ë‹ˆë‹¤
    visits_normalized = row['normalized_visits']
    color = colors.to_hex(cmap(visits_normalized))
    radius = 5 + (visits_normalized * 10) #5ëŠ” ê¸°ë³¸ í¬ê¸°, ì •ê·œí™”ëœ ê°’ì— ë”°ë¼ í¬ê¸°ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
    #ë°˜ì§€ë¦„ì„ í‚¤ìš°ê³  ì‹¶ë‹¤ë©´ 10ì„ ë” í° ìˆ«ìë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.
    folium.CircleMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        radius=radius,
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        weight=0.1,
        popup=f"ì •ë¥˜ì¥ëª…: {row['ì •ë¥˜ì¥ëª…']}<br>ë°©ë¬¸íšŸìˆ˜: {row['ë°©ë¬¸íšŸìˆ˜']}"  # íŒì—… ì¶”ê°€
    ).add_to(m)

# ì§€ë„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤
display(m)



"""ã€½ ë²„ìŠ¤ì •ë¥˜ì¥ ë°©ë¬¸íšŸìˆ˜ì™€ ì§€ê°€ë¥¼ í†µí•œ kmeans clusteringì„ ìœ„í•œ scree plot"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# ë¶€ì§€ ë°ì´í„°ì™€ ë²„ìŠ¤ ì •ë¥˜ì¥ ë°ì´í„°ë¥¼ ìœ„ë„/ê²½ë„ë¡œ ë§¤ì¹­í•˜ì—¬ ë²„ìŠ¤ ë°©ë¬¸ íšŸìˆ˜ë¥¼ ì¶”ê°€

#ìœ„ë„(lat)ì™€ ê²½ë„(lon)ì— ê°€ì¥ ê°€ê¹Œìš´ ë²„ìŠ¤ ì •ë¥˜ì¥ì„ bus_gumgok ë°ì´í„°í”„ë ˆì„ì—ì„œ ì°¾ì•„ì„œ, ê·¸ ì •ë¥˜ì¥ì˜ ì •ê·œí™”ëœ ë°©ë¬¸ íšŸìˆ˜(normalized_visits)ë¥¼ ë°˜í™˜
def find_nearest_bus_visits(lat, lon, bus_gumgok):
    distances = np.sqrt((bus_gumgok["ìœ„ë„"] - lat)**2 + (bus_gumgok["ê²½ë„"] - lon)**2)
    nearest_idx = distances.idxmin()
    return bus_gumgok.loc[nearest_idx, "normalized_visits"]

#gumgok ë°ì´í„°í”„ë ˆì„ì— "bus_visits"ë¼ëŠ” ìƒˆë¡œìš´ ì—´ì„ ìƒì„±í•˜ê³ , ê° í–‰ì— ëŒ€í•´ find_nearest_bus_visits í•¨ìˆ˜ê°€ ë°˜í™˜í•œ ê°’ì„ í•´ë‹¹ í–‰ì˜ "bus_visits" ì—´ì— ì €ì¥
land_gumgok["bus_visits"] = land_gumgok.apply(lambda row: find_nearest_bus_visits(row["ìœ„ë„"], row["ê²½ë„"], bus_gumgok), axis=1)

display(bus_gumgok)
display(land_gumgok)

# í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
features = land_gumgok[["ìœ„ë„", "ê²½ë„", "ê³µì‹œì§€ê°€ ( ì›/ ã¡)", "bus_visits"]].copy()

# í‘œì¤€í™” ì§„í–‰ (K-meansëŠ” ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì´ë¯€ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì • í•„ìˆ˜)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
display(scaled_features)

# ì ì ˆí•œ Kê°’ì„ ì°¾ê¸° ìœ„í•œ Elbow Method
inertia = []
k_values = range(1, 10)

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(8, 5))
plt.plot(k_values, inertia, marker='o', linestyle='-')
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Inertia")
plt.title("Elbow Method for Optimal K")
plt.show()

# K=3ê³¼ K=4 ë¹„êµ
k_values_to_test = [3, 4]
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

for idx, k in enumerate(k_values_to_test):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    land_gumgok[f"cluster_{k}"] = kmeans.fit_predict(scaled_features)

    scatter = axes[idx].scatter(land_gumgok["normalized_price"], land_gumgok["bus_visits"], c=land_gumgok[f"cluster_{k}"], cmap="viridis", edgecolors="k")
    axes[idx].set_title(f"K={k} í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼")
    axes[idx].set_xlabel("normalized_price")
    axes[idx].set_ylabel("bus_visits")

    # ì¸ë±ìŠ¤ í‘œì‹œ ì¶”ê°€
    for i, row in land_gumgok.iterrows():
        axes[idx].annotate(row.name, (row["normalized_price"], row["bus_visits"]))

plt.tight_layout()
plt.show()

#ë”°ë¼ì„œ k=4ë¡œ ê²°ì •
#k=4ì¼ ë•Œ ë™ê·¸ë¼ë¯¸ ìƒ‰ ë‹¤ë¥´ê²Œ í•´ì„œ ì‹œê°í™” ëª…í™•íˆ -> ê° ê·¸ë£¹ì˜ ì˜ë¯¸ ë¬¼ì–´ë³´ê¸° -> ê²°ì •

#ë”°ë¼ì„œ ë²„ìŠ¤ ì •ë¥˜ì¥ ì ìˆ˜ê°€ ë†’ê³  ì§€ëŒ€ê°€ ê°€ì¥ ë‚®ì€ 0, 1, 15ì˜ ë„ë¡œì ‘ë©´ì€ ë§¹ì§€ì´ê³  ì§€ê°€ê°€ ì ë‹¹í•˜ë©° ë²„ìŠ¤ì •ë¥˜ì¥ì˜ ì ìˆ˜ê°€ ë†’ì€ 19ë²ˆì€ ì•„íŒŒíŠ¸ë‹¨ì§€ì´ë¯€ë¡œ ì´ë“¤ê³¼ í•¨ê»˜ ë¬¶ì´ë©´ì„œ ì§€ê°€ê°€ ì ë‹¹í•˜ê³  ë²„ìŠ¤ì •ë¥˜ì¥ ë°©ë¬¸íšŸìˆ˜ê°€ ë¹„êµì  ë†’ì€ 16, 17ë²ˆìœ¼ë¡œ ì„ ì • ã„´

features

land_gumgok

display(m)

000

# ì •ìˆ˜ ë³€í™˜
#data['ìˆœìœ„'] = data['ìˆœìœ„'].apply(lambda x: int(x))

#data['ìˆœìœ„'] = data['ìˆœìœ„'].astype(int).copy()

# iterrows()ì—ì„œ í™•ì¸

print(data.dtypes)
print(type(data['ìˆœìœ„']))

for index, row in data.iterrows():
    row_df = row.to_frame().T

print(type(data['ìˆœìœ„']))


data['ìˆœìœ„'] = data['ìˆœìœ„'].apply(lambda x: int(x))


# iterrows()ì—ì„œ í™•ì¸
for index, row in data.iterrows():
    print(f"index: {index}, ìˆœìœ„: {row['ìˆœìœ„']}, type: {type(row['ìˆœìœ„'])}")



data = data.rename(index={0: 1, 1: 2, 2: 3})
print(data.index)

for index, row in data.iterrows():
       print(f"index: {index}, ìˆœìœ„: {row['ìˆœìœ„']}, type: {type(row['ìˆœìœ„'])}")

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆì‹œ ë°ì´í„°í”„ë ˆì„)
data = pd.DataFrame({
    'ë²ˆí˜¸': [7, 5, 6],
    'ìœ„ë„': [35.265342, 35.265632, 35.265723],  # ì˜ˆì‹œ ìœ„ë„
    'ê²½ë„': [129.017741, 129.017452, 129.016748],  # ì˜ˆì‹œ ê²½ë„
    'ìˆœìœ„': [1, 2, 3]   # ìˆœìœ„ ì¶”ê°€
})

# ë§ˆì»¤ ì¶”ê°€ (ìˆœìœ„ë³„ ìƒ‰ìƒ ì°¨ë³„í™”)
colors = {1: 'red', 2: 'blue', 3: 'green'}
for _, row in data.iterrows():
    folium.RegularPolygonMarker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        popup=f"ë²ˆí˜¸: {row['ë²ˆí˜¸']}, ìˆœìœ„: {row['ìˆœìœ„']}",
        number_of_sides=5,  # ë³„ ëª¨ì–‘ (5ê°í˜•)
        radius=10,  # ë§ˆì»¤ í¬ê¸°
        rotation=36,  # ë³„ ëª¨ì–‘ íšŒì „ ê°ë„ (ë³„ ëª¨ì–‘ì„ ìœ„í•´ 36ë„ íšŒì „)
        fill=True,
        fill_color=colors[int(row['ìˆœìœ„'])],  # ìƒ‰ìƒ ì§€ì •
        fill_opacity=0.7  # íˆ¬ëª…ë„
    ).add_to(m)
# ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ë°”ë¡œ ì§€ë„ ë³´ê¸° (Colab ë˜ëŠ” Jupyter í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥)
m

