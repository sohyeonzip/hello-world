# -*- coding: utf-8 -*-
"""부산 노인복지회관.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ilSzMvOjjnyiTtP5oqLTUrFZT950AI-9

📈 데이터 전처리
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')



"""📁 평균연령 데이터"""

df = pd.read_excel("/content/drive/MyDrive/프로젝트/평균연령.xlsx")
df = df.drop(df.index[0])
df = df.drop(df.columns[0], axis=1)
df = df.drop(df.columns[1], axis=1)
df = df.drop(df.columns[1], axis=1)
df = df.set_index('Unnamed: 1')
df.columns = [col.replace('Unnamed: 4', '평균연령') for col in df.columns]
df.index.name = None
df = df.drop(df.index[0])
display(df)

busan = df[df.index.str.contains('부산')]
busan = busan.drop(busan.index[:2])

import re
pattern = r".+(시|구)\s?"

busan.index = busan.index.str.replace(pattern, "", regex=True)

busan = busan.drop(index='')
busan = busan.drop(busan.index[-1])
busan = busan.drop(busan.index[-6])

busan = busan.rename(index={'기장군 기장읍' : '기장읍'})
busan = busan.rename(index={'기장군 장안읍' : '장안읍'})
busan = busan.rename(index={'기장군 정관읍' : '정관읍'})
busan = busan.rename(index={'기장군 일광읍' : '일광읍'})
busan = busan.rename(index={'기장군 철마면' : '철마면'})

busan.index = busan.index.str.replace('제', '', regex=False)

display(busan)



"""📁 고령자수 데이터"""

df2 = pd.read_excel("/content/drive/MyDrive/프로젝트/고령자수.xlsx")
df2 = df2.drop(df2.index[:1])
df2 = df2.set_index('Unnamed: 1')
df2.index.name = None
df2 = df2.drop(columns=['※ 매월 말일자 통계 현황'])
df2 = df2.drop(columns=[df2.columns[1]])
df2 = df2.drop(columns=[df2.columns[1]])
df2 = df2.drop(columns=[df2.columns[-1]])
df2 = df2.drop(columns=[df2.columns[-1]])

df2.columns = [col.replace('Unnamed: 2', '전체 인구  (명)') for col in df2.columns]
df2.columns = [col.replace('Unnamed: 5', '65세 이상 고령자 (명)') for col in df2.columns]
df2 = df2.drop(df2.index[0])
display(df2)

busan2 = df2[df2.index.str.contains('부산')]

import re
pattern = r".+(시|구)\s?"

busan2.index = busan2.index.str.replace(pattern, "", regex=True)

busan2 = busan2.drop(index='') #index는 매개변수로 사용 #busan2.index는 인덱스 값을 가져오는 객체
busan2 = busan2.drop(busan2.index[0])
busan2 = busan2.drop(busan2.index[-1])
busan2 = busan2.drop(busan2.index[-6])

busan2 = busan2.rename(index={'기장군 기장읍' : '기장읍'})
busan2 = busan2.rename(index={'기장군 장안읍' : '장안읍'})
busan2 = busan2.rename(index={'기장군 정관읍' : '정관읍'})
busan2 = busan2.rename(index={'기장군 일광읍' : '일광읍'})
busan2 = busan2.rename(index={'기장군 철마면' : '철마면'})

busan2.index = busan2.index.str.replace('제', '', regex=False)
display(busan2)



"""📁 기초연금수급자 데이터"""

df3 = pd.read_excel('/content/drive/MyDrive/프로젝트/기초연금수급자.xlsx')
df3 = df3.set_index('읍면동')
df3.index.name = None
df3 = df3.drop(df3.columns[0], axis=1) #df3 = df3.drop(columns=[df3.columns[0]]) #df3 = df3.drop(columns=['구군명'])
df3 = df3.drop(df3.columns[0], axis=1)
df3 = df3[~df3.index.str.contains('소계', na=False)]
df3.index = pd.Index(df3.index.to_series().ffill())

gu_indices = df3.index[df3.index.str.endswith('구')]
df3 = df3.drop(index=gu_indices)

df3 = df3.drop(columns=['성별'])
df3 = df3.drop(columns=['합계'])
display(df3)

dong_data = []

row_total = 0
current_dong = None

for index, row in df3.iterrows():
  dong = index

  if dong != current_dong:
    if current_dong is not None:
      dong_data.append([current_dong, row_total])
    row_total = 0
    current_dong = dong

  row_sum = row.sum()
  row_total += row_sum

dong_data.append([current_dong, row_total])
print(dong_data)

dong_df = pd.DataFrame(dong_data)
dong_df = dong_df.set_index(dong_df.columns[0])
dong_df.index.name = None
dong_df.columns = ['기초연금 수급자 수 (노인)']
dong_df = dong_df.drop(index = ['기장군']) #dong_df = dong_df.drop(data.index[-7])
display(dong_df)



busan.index.name = '동'
busan2.index.name = '동'
dong_df.index.name = '동'

merge_busan = pd.merge(busan, busan2, on='동', how='outer')
merge_busan = pd.merge(merge_busan, dong_df, on='동', how='outer')

merge_busan = merge_busan.drop(index='서2동')
merge_busan = merge_busan.drop(index='서1동')

merge_busan['전체 인구  (명)'] = merge_busan['전체 인구  (명)'].str.replace(',', '')
merge_busan['65세 이상 고령자 (명)'] = merge_busan['65세 이상 고령자 (명)'].str.replace(',', '')

#merge_busan.iloc[merge_busan.index.get_loc('선두구동'), 0] # 0 <-> merge_busan.columns.get_loc(merge_busan.columns[0]) #df.iloc[행 번호, 열 번호(위치)]
merge_busan.loc['선두구동', '평균연령'] = 57.7  #df.loc[행 인덱싱값, 열 인덱싱값]
merge_busan.loc['선두구동', '전체 인구  (명)'] = 2009
merge_busan.loc['선두구동', '65세 이상 고령자 (명)'] = 807

merge_busan.loc['거제1동', '평균연령'] = 45.1
merge_busan.loc['거제1동', '전체 인구  (명)'] = 27817
merge_busan.loc['거제1동', '65세 이상 고령자 (명)'] = 5761

merge_busan.loc['거제2동', '평균연령'] = 39.6
merge_busan.loc['거제2동', '전체 인구  (명)'] = 24924
merge_busan.loc['거제2동', '65세 이상 고령자 (명)'] = 3151

merge_busan.loc['거제3동', '평균연령'] = 52.5
merge_busan.loc['거제3동', '전체 인구  (명)'] = 9235
merge_busan.loc['거제3동', '65세 이상 고령자 (명)'] = 3069

merge_busan.loc['거제4동', '평균연령'] = 48.8
merge_busan.loc['거제4동', '전체 인구  (명)'] = 9430
merge_busan.loc['거제4동', '65세 이상 고령자 (명)'] = 2461

merge_busan.loc['구서1동', '평균연령'] = 46.9
merge_busan.loc['구서1동', '전체 인구  (명)'] = 18274
merge_busan.loc['구서1동', '65세 이상 고령자 (명)'] = 4086

merge_busan.loc['구서2동', '평균연령'] = 47.8
merge_busan.loc['구서2동', '전체 인구  (명)'] = 30575
merge_busan.loc['구서2동', '65세 이상 고령자 (명)'] = 7525

merge_busan.loc['구평동', '평균연령'] = 43.4
merge_busan.loc['구평동', '전체 인구  (명)'] = 12286
merge_busan.loc['구평동', '65세 이상 고령자 (명)'] = 2132

merge_busan.loc['구포1동', '평균연령'] = 49.5
merge_busan.loc['구포1동', '전체 인구  (명)'] = 14988
merge_busan.loc['구포1동', '65세 이상 고령자 (명)'] = 3964

merge_busan.loc['구포2동', '평균연령'] = 49.3
merge_busan.loc['구포2동', '전체 인구  (명)'] = 23144
merge_busan.loc['구포2동', '65세 이상 고령자 (명)'] = 5748

merge_busan.loc['구포3동', '평균연령'] = 50.6
merge_busan.loc['구포3동', '전체 인구  (명)'] = 17484
merge_busan.loc['구포3동', '65세 이상 고령자 (명)'] = 4546

merge_busan.loc['서1동'] = [58, 4288, 1751, 415]
merge_busan.loc['서2동'] = [54, 8087, 2771, 489]
merge_busan.loc['구서1동'] = [46.9, 18274, 4086, 223]
merge_busan.loc['구서2동'] = [47.8, 30575, 7525, 425]

merge_busan = merge_busan.drop(index=['일광면'])
merge_busan = merge_busan.dropna(subset=['기초연금 수급자 수 (노인)'])

display(merge_busan)
print(merge_busan.isnull().sum())

merge_busan = merge_busan.sort_values(by='동', ascending=True)

merge_busan['평균연령'] = merge_busan['평균연령'].astype(float)
merge_busan['전체 인구  (명)'] = merge_busan['전체 인구  (명)'].astype(int)
merge_busan['65세 이상 고령자 (명)'] = merge_busan['65세 이상 고령자 (명)'].astype(int)
merge_busan['기초연금 수급자 수 (노인)'] = merge_busan['기초연금 수급자 수 (노인)'].astype(int)

print(merge_busan.dtypes)

merge_busan['기초연금 수급자 비율 (노인)'] = merge_busan['기초연금 수급자 수 (노인)'] / merge_busan['65세 이상 고령자 (명)'] * 100
display(merge_busan)



"""📁 의료기관 데이터"""

df4 = pd.read_excel('/content/drive/MyDrive/프로젝트/병원정보서비스.xlsx')
df4 = df4[df4['시도코드명'] == '부산']
df4 = df4.drop(columns=['종별코드', '암호화요양기호', '시도코드', '시도코드명', '시군구코드', '시군구코드명', '우편번호', '전화번호', '병원홈페이지', '개설일자', '총의사수', '의과일반의 인원수', '의과인턴 인원수', '의과레지던트 인원수', '의과전문의 인원수', '치과일반의 인원수', '치과인턴 인원수', '치과레지던트 인원수', '치과전문의 인원수', '한방일반의 인원수', '한방인턴 인원수', '한방레지던트 인원수', '한방전문의 인원수', '조산사 인원수'])
df4 = df4.set_index('읍면동')
df4 = df4.sort_values(by='읍면동', ascending=True)
hospital = df4[~df4['종별코드명'].str.contains('보건')]
d_hospital = hospital.drop(columns=['주소', '종별코드명'])
display(d_hospital)



"""📁 공공보건기관 데이터"""

bogun = df4[(df4['종별코드명'] == '보건소') | (df4['종별코드명'] == '보건지소') | (df4['종별코드명'] == '보건진료소')] #df4[df4['종별코드명'].isin(['보건소', '보건지소', '보건진료소'])]
bogun = bogun.sort_values(by='읍면동', ascending=True)
d_bogun = bogun.drop(columns=['종별코드명', '주소'])
display(d_bogun)



"""📁 버스 정류장 데이터"""

bus = pd.read_csv('/content/drive/MyDrive/프로젝트/부산 버스정류장.csv',encoding='cp949')
bus = bus[bus['strd_date'] == 20250110]
bus = bus[['stps_id', 'stps_nm', 'stps_lgd_cdn_val', 'stps_ltd_cdn_val']]

bus = bus.rename(columns={'stps_id' : '정류장번호'})
bus = bus.rename(columns={'stps_nm' : '정류장명'})
bus = bus.rename(columns={'stps_lgd_cdn_val' : '경도'})
bus = bus.rename(columns={'stps_ltd_cdn_val' : '위도'})

bus = bus.reset_index()
bus = bus.drop(columns=['index'])
display(bus)

busstop = bus['정류장번호'].value_counts()
busstop = pd.DataFrame(busstop)
busstop = busstop.reset_index()
busstop = busstop.rename(columns={'count':'방문횟수'})
display(busstop)

bus_score = pd.merge(busstop, bus, on='정류장번호', how='left')
bus_score = bus_score.drop_duplicates()
display(bus_score)



""" 📁 지리 데이터"""

!pip install folium
!pip install geopandas

!pip install --upgrade fiona

import folium
import geopandas as gpd
from folium.plugins import HeatMap
from shapely.geometry import Point,Polygon,MultiPoint
from shapely.geometry import shape,LineString
from shapely.ops import cascaded_union

gdf_korea = gpd.read_file('/content/drive/MyDrive/프로젝트/BND_ADM_DONG_PG.shp')

codes = ['21010', '21020', '21030', '21040', '21050', '21060', '21070', '21080', '21090', '21100', '21110', '21120', '21130', '21140', '21150', '21510']
gdf_bs = gdf_korea[gdf_korea['ADM_CD'].str[:5].isin(codes)]

gdf_bs['geometry'] = gdf_bs['geometry'].apply(lambda x: shape(x).buffer(0))
gdf_bs = gdf_bs.to_crs('EPSG:4326')
display(gdf_bs)



"""버스정류장 데이터 행정동 적용"""

bus_score['동'] = None
for i, point in bus_score.iterrows():
  latitude = point['위도']
  longitude = point['경도']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      bus_score.at[i, '동'] = area['ADM_NM']
      break
display(bus_score)

i_bus_score = bus_score.dropna()
i_bus_score = i_bus_score.groupby('동')

f_bus = i_bus_score['방문횟수'].sum()
n_bus = i_bus_score['정류장명'].count()
display(f_bus)
display(n_bus)



"""의료기관 데이터 행정동 적용"""

d_hospital['동'] = None
for i, point in d_hospital.iterrows():
  latitude = point['좌표(Y)']
  logitude = point['좌표(X)']
  point_geom = Point(logitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      d_hospital.at[i, '동'] = area['ADM_NM']
      break

d_hospital = d_hospital.dropna(subset={'동'})
d_hospital = d_hospital.groupby('동')
d_hospital = d_hospital['동'].count()
d_hospital = d_hospital.to_frame()
d_hospital = d_hospital.rename(columns = {'동' : '의료기관'})
display(d_hospital)



"""공공보건기관 데이터 행정동 적용"""

d_bogun['동'] = None
for i, point in d_bogun.iterrows():
  latitude = point['좌표(Y)']
  longitude = point['좌표(X)']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      d_bogun.at[i, '동'] = area['ADM_NM']
      break

d_bogun = d_bogun[['동']]
d_bogun = d_bogun.groupby('동')
d_bogun = d_bogun['동'].count()
d_bogun = d_bogun.to_frame()
d_bogun = d_bogun.rename(columns={'동' : '공공보건기관'})
display(d_bogun)



"""📁 노인복지관 데이터"""

df5 = pd.read_csv('/content/drive/MyDrive/프로젝트/노인복지관.csv', encoding='cp949')

df5['동'] = None
for i, point in df5.iterrows():
  latitude = point['위도']
  longitude = point['경도']
  point_geom = Point(longitude, latitude)

  for j, area in gdf_bs.iterrows():
    if point_geom.within(area['geometry']):
      df5.at[i, '동'] = area['ADM_NM']
      break
display(df5)

grouped_df5 = df5.groupby('동')
senior_centor = grouped_df5['동'].count()
senior_centor = senior_centor.to_frame()
senior_centor = senior_centor.rename(columns={'동' : '노인복지회관'})
display(senior_centor)



"""📁 인구밀도 데이터"""

df6 = pd.read_excel('/content/drive/MyDrive/프로젝트/인구밀도.xls')

df6 = df6.drop(columns=['순위', '집계구번호', '비율(%)'])
df6 = df6.set_index('항목')
df6 = df6.rename(columns={'값' : '인구밀도 (명/㎢)'})
df6.index.name = '동'
display(df6)



"""📁 노령화지수 데이터"""

df7 = pd.read_excel('/content/drive/MyDrive/프로젝트/노령화지수.xls')

df7 = df7.drop(columns=['순위', '집계구번호', '비율(%)'])
df7 = df7.set_index('항목')
df7 = df7.rename(columns={'값' : '노령화지수'})
df7.index.name = '동'
display(df7)



"""📈 분석"""

data = pd.merge(merge_busan, d_hospital, on='동', how='outer')
data = pd.merge(data, d_bogun, on='동', how='outer')
data = pd.merge(data, f_bus, on='동', how='outer')
data = pd.merge(data, n_bus, on='동', how='outer')

data = data.fillna(0)
data['의료기관'] = data['의료기관'].astype(int)
data['공공보건기관'] = data['공공보건기관'].astype(int)
data['방문횟수'] = data['방문횟수'].astype(int)
data['정류장명'] = data['정류장명'].astype(int)

data = pd.merge(data, df6, on='동', how='outer')
data = pd.merge(data, df7, on='동', how='outer')
display(data)

print(data.isnull().sum())

scaler = StandardScaler()
data_scale = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)
data_scale = data_scale*10 + 50
display(data_scale)

#스케일링 -> scree plot 통해 최적의 주성분 갯수 설정 -> 스케일링된 자료 통해 주성분분석 -> 주성분 점수 통해 각 주성분에 대해 노인복지관 있는 곳 없는 곳 확률밀도함수 -> 노인복지회관 유무에 가장 영향력 있는 주성분 2개 선정 -> pc1과 pc4에 대해 kmeans clustering
#스케일링 -> 노인복지회관 있는 곳 없는 곳 확률밀도함수 -> 노인복지회관 유무에 영향력있는 변수 차등 가중치 부여 -> 재스케일링 -> 지표 생성하여 시각화



"""〽 scree plot"""

from sklearn.decomposition import PCA

pca_model = PCA()
pca_result = pca_model.fit_transform(data_scale)

print(pca_result)

plt.plot(range(1, len(pca_model.explained_variance_ratio_)+1), pca_model.explained_variance_ratio_, marker='o')
plt.xlabel('Number of Components')
plt.ylabel('Explained Variance')
plt.title('Scree Plot')
plt.show()

#주성분 개수를 구하기 위해 scree plot 분석 결과 그래프가 4지점까지 급격하게 하락하고 그 뒤로는 완만한 것을 확인할 수 있음 따라서 엘보우 포인트가 주성분이 4개일 때로 가정, 주성분이 더 많을 때와 차이가 크게 나지 않는 것을 확인할 수 있음

#scree plot을 통해 얻은 주성분 개수를 통해 11개의 차원을 4개의 차원으로 축소시킨 데이터(주성분 점수)
pca = PCA(n_components=4)
pca_result = pca.fit_transform(data_scale)
print(pca_result)

#PCA 분산 설명력
pca_variance_ratio = pca.explained_variance_ratio_
print(pca_variance_ratio)

#주성분계수
loadings = pca.components_
print(loadings)

pc = pd.DataFrame(loadings.T, index=data_scale.columns, columns=['PC1', 'PC2', 'PC3', 'PC4'])
display(pc)



"""〽 확률밀도함수"""

dataframe = pd.merge(data, senior_centor, on='동', how='outer')
dataframe = dataframe.fillna(0)
dataframe['노인복지회관'] = dataframe['노인복지회관'].astype(int)
display(dataframe)

#노인복지회관 유무에 따라 데이터 분리
df_no_senior_centor = dataframe[dataframe['노인복지회관'] == 0]
df_senior_centor = dataframe[dataframe['노인복지회관'] == 1]
display(df_no_senior_centor)
display(df_senior_centor)

#분리된 데이터 각 스케일링 후 데이터프레임으로 변환
scaler = StandardScaler()

no_senior_scaled = scaler.fit_transform(df_no_senior_centor)
no_senior_scaled_df = pd.DataFrame(no_senior_scaled, columns=df_no_senior_centor.columns)
display(no_senior_scaled_df)

senior_scaled = scaler.fit_transform(df_senior_centor)
senior_scaled_df = pd.DataFrame(senior_scaled, columns=df_senior_centor.columns)
display(senior_scaled_df)

#확률밀도함수 생성
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm

plt.rc("font", family="Liberation Serif")
plt.rcParams["axes.unicode_minus"] = False

# 비교할 변수 목록
columns = [
    "평균연령", "전체 인구  (명)", "65세 이상 고령자 (명)", "기초연금 수급자 수 (노인)",
    "기초연금 수급자 비율 (노인)", "의료기관", "공공보건기관", "정류장명", "방문횟수", "인구밀도 (명/㎢)",
    "노령화지수"
]

# 그래프 설정
plt.figure(figsize=(15, 24))
for i, col in enumerate(columns, 1):
    plt.subplot(6, 2, i)
    sns.kdeplot(no_senior_scaled_df[col], label="x", fill=True, alpha=0.5)
    sns.kdeplot(senior_scaled_df[col], label="o", fill=True, alpha=0.5)
    plt.legend()
    plt.title(f"{col}에 따른 확률밀도함수")
plt.tight_layout()
plt.show()

# ✅ 기존 KDE 가중치 기존 KDE 기반 가중치는 변수별 분포의 차이를 고려해서 설정했어. 즉, 변수들이 지역별로 얼마나 차이가 나는지를 반영
#KDE 가중치 설정 논리 KDE(커널 밀도 추정, Kernel Density Estimation) 그래프를 분석한 결과,
#값의 분포 차이가 큰 변수 → 높은 가중치 값의 차이가 적은 변수 → 낮은 가중치
#kde_weights = np.array([0.05, 0.05, 0.10, 0.20, 0.20, 0.15, 0.15, 0.05, 0.05, 0.05, 0.10])



"""〽 변수별 가중치 계산 후 지표 설정"""

# ✅ PCA 분산 설명력
pca_variance_ratio = np.array([0.36063063, 0.22569202, 0.13786348, 0.08059372])

# ✅ PCA 로딩값
pca_loadings = loadings.T

# ✅ PCA 가중치 계산 (절댓값 × 분산 설명력)
pca_weights = np.sum(np.abs(pca_loadings) * pca_variance_ratio, axis=1)

# ✅ 기존 KDE 가중치
kde_weights = np.array([0.05, 0.05, 0.10, 0.20, 0.20, 0.15, 0.15, 0.05, 0.05, 0.05, 0.10])

# ✅ 최종 가중치 (PCA 50% + KDE 50%)
final_weights = 0.5 * pca_weights + 0.5 * kde_weights

# ✅ 가중치 DataFrame 생성
columns = ["평균연령", "전체 인구", "65세 이상 고령자", "기초연금 수급자 수", "기초연금 수급자 비율",
           "의료기관", "공공보건기관", "방문횟수", "정류장 수", "인구밀도", "노령화지수"]
weights_df = pd.DataFrame({"변수": columns, "최종 가중치": final_weights})

# ✅ 결과 출력
display(weights_df)

# ✅ 지역별 지표 계산 (각 변수 값 * 가중치 합)
region_scores = np.dot(data_scale, final_weights)

# ✅ 결과 출력
regions = data.index.tolist()
result_df = pd.DataFrame({"행정동": regions, "지표": region_scores})
display(result_df)

#지표점수 기준으로 내림차순
scaler = StandardScaler()
dataframe = pd.DataFrame(scaler.fit_transform(dataframe), columns=dataframe.columns)
dataframe = dataframe*10 + 50

dataframe = pd.concat([dataframe, result_df], axis=1)
dataframe = dataframe.sort_values(by='지표', ascending=False)
display(dataframe)



"""〽 지도 시각화"""

result_df = result_df.set_index('행정동')
gdf_index = pd.merge(gdf_bs, result_df['지표'], left_on='ADM_NM', right_index=True)
display(gdf_index)

#지표에 따른 시각화
m=folium.Map(location=[35.1796, 129.0756], zoom_start=11)

folium.Choropleth(
    geo_data=gdf_index,
    data=gdf_index,
    columns=['ADM_NM', '지표'],
    key_on='feature.properties.ADM_NM',
    fill_color='YlGnBu',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='지표'
).add_to(m)
folium.GeoJson(gdf_index).add_to(m)

display(m)

#현재 존재하는 노인복지회관 위치 추가
for idx, row in df5.iterrows():
  folium.CircleMarker(
      location=[row['위도'], row['경도']],
      radius=15,
      color='red',
      fill=True,
      weight=0.1
  ).add_to(m)

display(m)

#지표를 통한 시각화와 현재 존재하는 노인복지회관의 위치 파악을 통해 지역을 금곡동으로 선정

plotly



"""〽 금곡동 지가 데이터"""

import requests
import pandas as pd

file_path = '/content/drive/MyDrive/프로젝트/금곡동 지가.xlsx'

land_gumgok = pd.read_excel(file_path)
land_gumgok = land_gumgok.dropna()
land_gumgok.columns = land_gumgok.iloc[0]
land_gumgok.drop(index=1, inplace=True)
land_gumgok.index = land_gumgok['일련 번호']
land_gumgok.columns.name = None
land_gumgok = land_gumgok.drop(columns=['일련 번호', '지 목', '지리적 위치', '형상 지세']) #열 삭제 #land_gumgok.drop(land_gumgok.columns[0], axis=1)
land_gumgok = land_gumgok.reset_index(drop=True)

display(land_gumgok)

#위도 경도 추가
land_gumgok['위도'] = None
land_gumgok['경도'] = None

latitude_values = [35.264806992462, 35.2628328140424, 35.266174832219, 35.266892790289, 35.2641924114557, 35.2657228187836, 35.265631953833, 35.2653420946788, 35.2649738413425, 35.2651331955503, 35.2649255240571, 35.2644468402776, 35.2645766278052, 35.2644330101972, 35.2639785286683, 35.2618801447748, 35.2623833498672, 35.2623142473772, 35.2631223714243, 35.2606828277845]
longitude_values = [129.038142717264, 129.022797131054, 129.017764116584, 129.017968937041, 129.020164496182, 129.016747972491, 129.017452117121, 129.017741265492, 129.019401364743, 129.016569421171, 129.017026081343, 129.017198364434, 129.016051298328, 129.016547011818, 129.01621897914, 129.021037807019, 129.016026837158, 129.015501364102, 129.019242131179, 129.015196386607]

for i in range(len(latitude_values)):
    if i in land_gumgok.index:
      land_gumgok.loc[i, '위도'] = latitude_values[i]

for i in range(len(longitude_values)):
    if i in land_gumgok.index:
      land_gumgok.loc[i, '경도'] = longitude_values[i]

display(land_gumgok)



"""〽 금곡동 지가 시각화"""

import folium
import pandas as pd
import geopandas as gpd
from folium.plugins import HeatMap
from shapely.geometry import Point,Polygon,MultiPoint
from shapely.geometry import shape,LineString
from shapely.ops import cascaded_union
import matplotlib.cm as cm
import matplotlib.colors as mcolors
import matplotlib.colors as colors
from matplotlib.colors import LinearSegmentedColormap

data_dict = {}
for index, row in land_gumgok.iterrows():
    data_dict[index] = {'위도': None, '경도': None}

# 위도, 경도 값을 차례대로 넣어줌
for index, (latitude, longitude) in enumerate(zip(latitude_values, longitude_values)):
    if index in data_dict:
        data_dict[index]['위도'] = latitude
        data_dict[index]['경도'] = longitude

# 새로운 딕셔너리를 사용해서 데이터프레임 업데이트
for index, values in data_dict.items():
    land_gumgok.loc[index, '위도'] = values['위도']
    land_gumgok.loc[index, '경도'] = values['경도']

# 지도 생성
map_center = [land_gumgok['위도'].mean(), land_gumgok['경도'].mean()]  # 위도와 경도의 평균값으로 지도 중심 설정
m = folium.Map(location=map_center, zoom_start=15)

# 공시지가 정규화
min_price = land_gumgok['공시지가 ( 원/ ㎡)'].min()
max_price = land_gumgok['공시지가 ( 원/ ㎡)'].max()
land_gumgok['normalized_price'] = (land_gumgok['공시지가 ( 원/ ㎡)'] - min_price) / (max_price - min_price)

# 색상 맵 생성 (YlGn 사용)
cmap = cm.get_cmap('YlGn')

# 원형 마커 추가
for index, row in land_gumgok.iterrows():
    price = row['normalized_price']
    color = colors.to_hex(cmap(price))  # 정규화된 값으로 색상 결정
    radius = 10 # 모든 원의 크기를 통일시켰습니다.
    folium.CircleMarker(
        location=[row['위도'], row['경도']],
        radius=radius,  # 모든 원의 크기를 통일시켰습니다.
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        popup=f"소재지: {row['소재지']}<br>공시지가: {row['공시지가 ( 원/ ㎡)']}"  # 팝업 추가
    ).add_to(m)

    # 인덱스 텍스트 레이블
    folium.map.Marker(
        [row['위도'], row['경도']],
        icon=folium.DivIcon(html=f"<div style='font-size: 8pt; color : black; font-weight: bold'>{index}</div>")
    ).add_to(m)

# 지도 표시
display(m)

#맹지와 아파드지대인 0, 1, 15, 19번 데이터 삭제
land_gumgok = land_gumgok.drop([0, 1, 15, 19])

data_dict = {}
for index, row in land_gumgok.iterrows():
    data_dict[index] = {'위도': None, '경도': None}

# 위도, 경도 값을 차례대로 넣어줌
for index, (latitude, longitude) in enumerate(zip(latitude_values, longitude_values)):
    if index in data_dict:
        data_dict[index]['위도'] = latitude
        data_dict[index]['경도'] = longitude

# 새로운 딕셔너리를 사용해서 데이터프레임 업데이트
for index, values in data_dict.items():
    land_gumgok.loc[index, '위도'] = values['위도']
    land_gumgok.loc[index, '경도'] = values['경도']

# 지도 생성
map_center = [land_gumgok['위도'].mean(), land_gumgok['경도'].mean()]  # 위도와 경도의 평균값으로 지도 중심 설정
m = folium.Map(location=map_center, zoom_start=15)

# 공시지가 정규화
min_price = land_gumgok['공시지가 ( 원/ ㎡)'].min()
max_price = land_gumgok['공시지가 ( 원/ ㎡)'].max()
land_gumgok['normalized_price'] = (land_gumgok['공시지가 ( 원/ ㎡)'] - min_price) / (max_price - min_price)

# 색상 맵 생성 (YlGn 사용)
cmap = cm.get_cmap('YlGn')

# 원형 마커 추가
for index, row in land_gumgok.iterrows():
    price = row['normalized_price']
    color = colors.to_hex(cmap(price))  # 정규화된 값으로 색상 결정
    radius = 10 # 모든 원의 크기를 통일시켰습니다.
    folium.CircleMarker(
        location=[row['위도'], row['경도']],
        radius=radius,  # 모든 원의 크기를 통일시켰습니다.
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        popup=f"소재지: {row['소재지']}<br>공시지가: {row['공시지가 ( 원/ ㎡)']}"  # 팝업 추가
    ).add_to(m)

    # 인덱스 텍스트 레이블
    folium.map.Marker(
        [row['위도'], row['경도']],
        icon=folium.DivIcon(html=f"<div style='font-size: 8pt; color : black; font-weight: bold'>{index}</div>")
    ).add_to(m)

# 지도 표시
display(m)



"""〽 금곡동 버스정류장 방문횟수 데이터 추가"""

bus_gumgok = bus_score[bus_score['동'] == '금곡동']
display(bus_gumgok)

# 방문 횟수를 기준으로 정규화합니다
min_visits = bus_gumgok['방문횟수'].min()
max_visits = bus_gumgok['방문횟수'].max()
bus_gumgok['normalized_visits'] = (bus_gumgok['방문횟수'] - min_visits) / (max_visits - min_visits)

# 색상 맵을 생성합니다 (예: YlGnBu 사용)
cmap = cm.get_cmap('Oranges')

for index, row in bus_gumgok.iterrows():
    # 정규화된 방문 횟수를 기준으로 색상과 반지름을 결정합니다
    visits_normalized = row['normalized_visits']
    color = colors.to_hex(cmap(visits_normalized))
    radius = 5 + (visits_normalized * 10) #5는 기본 크기, 정규화된 값에 따라 크기를 증가시킵니다.
    #반지름을 키우고 싶다면 10을 더 큰 숫자로 바꿔줍니다.
    folium.CircleMarker(
        location=[row['위도'], row['경도']],
        radius=radius,
        color=color,
        fill=True,
        fill_color=color,
        fill_opacity=0.7,
        weight=0.1,
        popup=f"정류장명: {row['정류장명']}<br>방문횟수: {row['방문횟수']}"  # 팝업 추가
    ).add_to(m)

# 지도를 표시합니다
display(m)



"""〽 버스정류장 방문횟수와 지가를 통한 kmeans clustering을 위한 scree plot"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# 부지 데이터와 버스 정류장 데이터를 위도/경도로 매칭하여 버스 방문 횟수를 추가

#위도(lat)와 경도(lon)에 가장 가까운 버스 정류장을 bus_gumgok 데이터프레임에서 찾아서, 그 정류장의 정규화된 방문 횟수(normalized_visits)를 반환
def find_nearest_bus_visits(lat, lon, bus_gumgok):
    distances = np.sqrt((bus_gumgok["위도"] - lat)**2 + (bus_gumgok["경도"] - lon)**2)
    nearest_idx = distances.idxmin()
    return bus_gumgok.loc[nearest_idx, "normalized_visits"]

#gumgok 데이터프레임에 "bus_visits"라는 새로운 열을 생성하고, 각 행에 대해 find_nearest_bus_visits 함수가 반환한 값을 해당 행의 "bus_visits" 열에 저장
land_gumgok["bus_visits"] = land_gumgok.apply(lambda row: find_nearest_bus_visits(row["위도"], row["경도"], bus_gumgok), axis=1)

display(bus_gumgok)
display(land_gumgok)

# 클러스터링을 위한 데이터 준비
features = land_gumgok[["위도", "경도", "공시지가 ( 원/ ㎡)", "bus_visits"]].copy()

# 표준화 진행 (K-means는 거리 기반 알고리즘이므로 스케일 조정 필수)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
display(scaled_features)

# 적절한 K값을 찾기 위한 Elbow Method
inertia = []
k_values = range(1, 10)

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# 결과 시각화
plt.figure(figsize=(8, 5))
plt.plot(k_values, inertia, marker='o', linestyle='-')
plt.xlabel("Number of Clusters (K)")
plt.ylabel("Inertia")
plt.title("Elbow Method for Optimal K")
plt.show()

# K=3과 K=4 비교
k_values_to_test = [3, 4]
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

for idx, k in enumerate(k_values_to_test):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    land_gumgok[f"cluster_{k}"] = kmeans.fit_predict(scaled_features)

    scatter = axes[idx].scatter(land_gumgok["normalized_price"], land_gumgok["bus_visits"], c=land_gumgok[f"cluster_{k}"], cmap="viridis", edgecolors="k")
    axes[idx].set_title(f"K={k} 클러스터링 결과")
    axes[idx].set_xlabel("normalized_price")
    axes[idx].set_ylabel("bus_visits")

    # 인덱스 표시 추가
    for i, row in land_gumgok.iterrows():
        axes[idx].annotate(row.name, (row["normalized_price"], row["bus_visits"]))

plt.tight_layout()
plt.show()

#따라서 k=4로 결정
#k=4일 때 동그라미 색 다르게 해서 시각화 명확히 -> 각 그룹의 의미 물어보기 -> 결정

#따라서 버스 정류장 점수가 높고 지대가 가장 낮은 0, 1, 15의 도로접면은 맹지이고 지가가 적당하며 버스정류장의 점수가 높은 19번은 아파트단지이므로 이들과 함께 묶이면서 지가가 적당하고 버스정류장 방문횟수가 비교적 높은 16, 17번으로 선정 ㄴ

features

land_gumgok

display(m)

000

# 정수 변환
#data['순위'] = data['순위'].apply(lambda x: int(x))

#data['순위'] = data['순위'].astype(int).copy()

# iterrows()에서 확인

print(data.dtypes)
print(type(data['순위']))

for index, row in data.iterrows():
    row_df = row.to_frame().T

print(type(data['순위']))


data['순위'] = data['순위'].apply(lambda x: int(x))


# iterrows()에서 확인
for index, row in data.iterrows():
    print(f"index: {index}, 순위: {row['순위']}, type: {type(row['순위'])}")



data = data.rename(index={0: 1, 1: 2, 2: 3})
print(data.index)

for index, row in data.iterrows():
       print(f"index: {index}, 순위: {row['순위']}, type: {type(row['순위'])}")

# 데이터 불러오기 (예시 데이터프레임)
data = pd.DataFrame({
    '번호': [7, 5, 6],
    '위도': [35.265342, 35.265632, 35.265723],  # 예시 위도
    '경도': [129.017741, 129.017452, 129.016748],  # 예시 경도
    '순위': [1, 2, 3]   # 순위 추가
})

# 마커 추가 (순위별 색상 차별화)
colors = {1: 'red', 2: 'blue', 3: 'green'}
for _, row in data.iterrows():
    folium.RegularPolygonMarker(
        location=[row['위도'], row['경도']],
        popup=f"번호: {row['번호']}, 순위: {row['순위']}",
        number_of_sides=5,  # 별 모양 (5각형)
        radius=10,  # 마커 크기
        rotation=36,  # 별 모양 회전 각도 (별 모양을 위해 36도 회전)
        fill=True,
        fill_color=colors[int(row['순위'])],  # 색상 지정
        fill_opacity=0.7  # 투명도
    ).add_to(m)
# 노트북 환경에서 바로 지도 보기 (Colab 또는 Jupyter 환경에서 실행 가능)
m

